{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% Project: Cell Tracking in Microscopy Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from vidstab import VidStab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added frame_0000.png to video.\n",
      "Added frame_0001.png to video.\n",
      "Added frame_0002.png to video.\n",
      "Added frame_0003.png to video.\n",
      "Added frame_0004.png to video.\n",
      "Added frame_0005.png to video.\n",
      "Added frame_0006.png to video.\n",
      "Added frame_0007.png to video.\n",
      "Added frame_0008.png to video.\n",
      "Added frame_0009.png to video.\n",
      "Added frame_0010.png to video.\n",
      "Added frame_0011.png to video.\n",
      "Added frame_0012.png to video.\n",
      "Added frame_0013.png to video.\n",
      "Added frame_0014.png to video.\n",
      "Added frame_0015.png to video.\n",
      "Added frame_0016.png to video.\n",
      "Added frame_0017.png to video.\n",
      "Added frame_0018.png to video.\n",
      "Added frame_0019.png to video.\n",
      "Added frame_0020.png to video.\n",
      "Added frame_0021.png to video.\n",
      "Added frame_0022.png to video.\n",
      "Added frame_0023.png to video.\n",
      "Added frame_0024.png to video.\n",
      "Added frame_0025.png to video.\n",
      "Added frame_0026.png to video.\n",
      "Added frame_0027.png to video.\n",
      "Added frame_0028.png to video.\n",
      "Added frame_0029.png to video.\n",
      "Added frame_0030.png to video.\n",
      "Added frame_0031.png to video.\n",
      "Added frame_0032.png to video.\n",
      "Added frame_0033.png to video.\n",
      "Added frame_0034.png to video.\n",
      "Added frame_0035.png to video.\n",
      "Added frame_0036.png to video.\n",
      "Added frame_0037.png to video.\n",
      "Added frame_0038.png to video.\n",
      "Added frame_0039.png to video.\n",
      "Added frame_0040.png to video.\n",
      "Added frame_0041.png to video.\n",
      "Added frame_0042.png to video.\n",
      "Added frame_0043.png to video.\n",
      "Added frame_0044.png to video.\n",
      "Added frame_0045.png to video.\n",
      "Added frame_0046.png to video.\n",
      "Added frame_0047.png to video.\n",
      "Added frame_0048.png to video.\n",
      "Added frame_0049.png to video.\n",
      "Added frame_0050.png to video.\n",
      "Added frame_0051.png to video.\n",
      "Added frame_0052.png to video.\n",
      "Added frame_0053.png to video.\n",
      "Added frame_0054.png to video.\n",
      "Added frame_0055.png to video.\n",
      "Added frame_0056.png to video.\n",
      "Added frame_0057.png to video.\n",
      "Added frame_0058.png to video.\n",
      "Added frame_0059.png to video.\n",
      "Added frame_0060.png to video.\n",
      "Added frame_0061.png to video.\n",
      "Added frame_0062.png to video.\n",
      "Added frame_0063.png to video.\n",
      "Added frame_0064.png to video.\n",
      "Added frame_0065.png to video.\n",
      "Added frame_0066.png to video.\n",
      "Added frame_0067.png to video.\n",
      "Added frame_0068.png to video.\n",
      "Added frame_0069.png to video.\n",
      "Added frame_0070.png to video.\n",
      "Added frame_0071.png to video.\n",
      "Added frame_0072.png to video.\n",
      "Added frame_0073.png to video.\n",
      "Added frame_0074.png to video.\n",
      "Added frame_0075.png to video.\n",
      "Added frame_0076.png to video.\n",
      "Added frame_0077.png to video.\n",
      "Added frame_0078.png to video.\n",
      "Added frame_0079.png to video.\n",
      "Added frame_0080.png to video.\n",
      "Added frame_0081.png to video.\n",
      "Added frame_0082.png to video.\n",
      "Added frame_0083.png to video.\n",
      "Added frame_0084.png to video.\n",
      "Added frame_0085.png to video.\n",
      "Added frame_0086.png to video.\n",
      "Added frame_0087.png to video.\n",
      "Added frame_0088.png to video.\n",
      "Added frame_0089.png to video.\n",
      "Added frame_0090.png to video.\n",
      "Added frame_0091.png to video.\n",
      "Added frame_0092.png to video.\n",
      "Added frame_0093.png to video.\n",
      "Added frame_0094.png to video.\n",
      "Added frame_0095.png to video.\n",
      "Added frame_0096.png to video.\n",
      "Added frame_0097.png to video.\n",
      "Added frame_0098.png to video.\n",
      "Added frame_0099.png to video.\n",
      "Added frame_0100.png to video.\n",
      "Added frame_0101.png to video.\n",
      "Added frame_0102.png to video.\n",
      "Added frame_0103.png to video.\n",
      "Added frame_0104.png to video.\n",
      "Added frame_0105.png to video.\n",
      "Added frame_0106.png to video.\n",
      "Added frame_0107.png to video.\n",
      "Added frame_0108.png to video.\n",
      "Added frame_0109.png to video.\n",
      "Added frame_0110.png to video.\n",
      "Added frame_0111.png to video.\n",
      "Added frame_0112.png to video.\n",
      "Added frame_0113.png to video.\n",
      "Added frame_0114.png to video.\n",
      "Added frame_0115.png to video.\n",
      "Added frame_0116.png to video.\n",
      "Added frame_0117.png to video.\n",
      "Added frame_0118.png to video.\n",
      "Added frame_0119.png to video.\n",
      "Added frame_0120.png to video.\n",
      "Added frame_0121.png to video.\n",
      "Added frame_0122.png to video.\n",
      "Added frame_0123.png to video.\n",
      "Added frame_0124.png to video.\n",
      "Added frame_0125.png to video.\n",
      "Added frame_0126.png to video.\n",
      "Added frame_0127.png to video.\n",
      "Added frame_0128.png to video.\n",
      "Added frame_0129.png to video.\n",
      "Added frame_0130.png to video.\n",
      "Added frame_0131.png to video.\n",
      "Added frame_0132.png to video.\n",
      "Added frame_0133.png to video.\n",
      "Added frame_0134.png to video.\n",
      "Added frame_0135.png to video.\n",
      "Added frame_0136.png to video.\n",
      "Added frame_0137.png to video.\n",
      "Added frame_0138.png to video.\n",
      "Added frame_0139.png to video.\n",
      "Added frame_0140.png to video.\n",
      "Added frame_0141.png to video.\n",
      "Added frame_0142.png to video.\n",
      "Added frame_0143.png to video.\n",
      "Added frame_0144.png to video.\n",
      "Added frame_0145.png to video.\n",
      "Added frame_0146.png to video.\n",
      "Added frame_0147.png to video.\n",
      "Added frame_0148.png to video.\n",
      "Added frame_0149.png to video.\n",
      "Added frame_0150.png to video.\n",
      "Added frame_0151.png to video.\n",
      "Added frame_0152.png to video.\n",
      "Added frame_0153.png to video.\n",
      "Added frame_0154.png to video.\n",
      "Added frame_0155.png to video.\n",
      "Added frame_0156.png to video.\n",
      "Added frame_0157.png to video.\n",
      "Added frame_0158.png to video.\n",
      "Added frame_0159.png to video.\n",
      "Added frame_0160.png to video.\n",
      "Added frame_0161.png to video.\n",
      "Added frame_0162.png to video.\n",
      "Added frame_0163.png to video.\n",
      "Added frame_0164.png to video.\n",
      "Added frame_0165.png to video.\n",
      "Added frame_0166.png to video.\n",
      "Added frame_0167.png to video.\n",
      "Added frame_0168.png to video.\n",
      "Added frame_0169.png to video.\n",
      "Added frame_0170.png to video.\n",
      "Added frame_0171.png to video.\n",
      "Added frame_0172.png to video.\n",
      "Added frame_0173.png to video.\n",
      "Added frame_0174.png to video.\n",
      "Added frame_0175.png to video.\n",
      "Added frame_0176.png to video.\n",
      "Added frame_0177.png to video.\n",
      "Added frame_0178.png to video.\n",
      "Added frame_0179.png to video.\n",
      "Added frame_0180.png to video.\n",
      "Added frame_0181.png to video.\n",
      "Added frame_0182.png to video.\n",
      "Added frame_0183.png to video.\n",
      "Added frame_0184.png to video.\n",
      "Added frame_0185.png to video.\n",
      "Added frame_0186.png to video.\n",
      "Added frame_0187.png to video.\n",
      "Added frame_0188.png to video.\n",
      "Added frame_0189.png to video.\n",
      "Added frame_0190.png to video.\n",
      "Added frame_0191.png to video.\n",
      "Added frame_0192.png to video.\n",
      "Added frame_0193.png to video.\n",
      "Added frame_0194.png to video.\n",
      "Added frame_0195.png to video.\n",
      "Added frame_0196.png to video.\n",
      "Added frame_0197.png to video.\n",
      "Added frame_0198.png to video.\n",
      "Added frame_0199.png to video.\n",
      "Added frame_0200.png to video.\n",
      "Added frame_0201.png to video.\n",
      "Added frame_0202.png to video.\n",
      "Added frame_0203.png to video.\n",
      "Added frame_0204.png to video.\n",
      "Added frame_0205.png to video.\n",
      "Added frame_0206.png to video.\n",
      "Added frame_0207.png to video.\n",
      "Added frame_0208.png to video.\n",
      "Added frame_0209.png to video.\n",
      "Added frame_0210.png to video.\n",
      "Added frame_0211.png to video.\n",
      "Added frame_0212.png to video.\n",
      "Added frame_0213.png to video.\n",
      "Added frame_0214.png to video.\n",
      "Added frame_0215.png to video.\n",
      "Added frame_0216.png to video.\n",
      "Added frame_0217.png to video.\n",
      "Added frame_0218.png to video.\n",
      "Added frame_0219.png to video.\n",
      "Video saved as Film2_15fps.avi\n"
     ]
    }
   ],
   "source": [
    "def display_tif_stack(input_path):\n",
    "\n",
    "    # Read the multipage TIFF file\n",
    "    tiff_stack = tifffile.imread(input_path)\n",
    "\n",
    "    # Invert the image but no need\n",
    "    # tiff_stack = ~tiff_stack\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the first frame\n",
    "    im = ax.imshow(tiff_stack[0], cmap='gray')\n",
    "\n",
    "    # Update function for animation\n",
    "    def update(frame):\n",
    "        im.set_array(tiff_stack[frame])\n",
    "        return [im]\n",
    "\n",
    "    # Create the animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(tiff_stack), interval=1, blit=False) # interval in milliseconds\n",
    "    print(len(tiff_stack), \"frames\")\n",
    "\n",
    "    # Show the animation\n",
    "    plt.show()\n",
    "\n",
    "# display_tiff_video(\"films/Film 1.tif\")\n",
    "\n",
    "def tif_stack_to_png_images(input_tiff, output_folder, file_prefix='png_frame'):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Read the TIFF file (stack)\n",
    "    tiff_stack = tifffile.imread(input_tiff)\n",
    "\n",
    "    # Iterate through each frame in the stack\n",
    "    for i, frame in enumerate(tiff_stack):\n",
    "        # Normalize the intensity values to the range [0, 255]\n",
    "        min_val = np.min(frame)\n",
    "        max_val = np.max(frame)\n",
    "        normalized_frame = 255 * (frame - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # Convert the normalized frame to uint8\n",
    "        normalized_frame_uint8 = normalized_frame.astype(np.uint8)\n",
    "        \n",
    "        # Convert the normalized frame to a PIL image\n",
    "        normalized_image_pil = Image.fromarray(normalized_frame_uint8)\n",
    "        \n",
    "        # Generate the output PNG filename\n",
    "        output_filename = f\"{file_prefix}_{i:04d}.png\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        # Save the frame as PNG\n",
    "        normalized_image_pil.save(output_path)\n",
    "\n",
    "        print(f\"Added {output_filename} to {output_folder}\")\n",
    "\n",
    "    print(f\"Saved {len(tiff_stack)} frames as normalized PNGs in {output_folder}\")\n",
    "\n",
    "    # usage: tif_stack_to_png_normalized(input_tiff, output_folder, file_prefix='png_frame')\n",
    "\n",
    "# tif_stack_to_png_images(\"Film 2.tif\", \"film2_png_frames\", file_prefix='frame')\n",
    "\n",
    "def frames_to_video(input_folder, output_video, frame_rate=30, codec='XVID'):\n",
    "    \"\"\"\n",
    "    Converts a series of PNG image frames into a video file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder (str): Path to the folder containing PNG image frames.\n",
    "    - output_video (str): Path where the output video file will be saved.\n",
    "    - frame_rate (int): Frame rate of the output video (default: 30).\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Collects all PNG files from the input folder.\n",
    "    2. Reads the first image to determine video dimensions.\n",
    "    3. Creates a VideoWriter object with the specified codec and frame rate.\n",
    "    4. Iterates through all images, adding each as a frame to the video.\n",
    "    5. Saves the resulting video file.\n",
    "\n",
    "    Note: Assumes all PNG files in the input folder are valid video frames\n",
    "    and have consistent dimensions.\n",
    "    \"\"\"\n",
    "    # Get list of all PNG files in the folder, sorted by name\n",
    "    image_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.png')])\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No PNG files found in the input folder.\")\n",
    "        return\n",
    "\n",
    "    # Read the first image to determine the frame size (width, height)\n",
    "    first_image_path = os.path.join(input_folder, image_files[0])\n",
    "    first_frame = cv2.imread(first_image_path)\n",
    "    height, width, layers = first_frame.shape\n",
    "\n",
    "    # Define the video codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)  # You can also use 'XVID' for .avi format mp4v\n",
    "    video = cv2.VideoWriter(output_video, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    # Iterate over each image and write it to the video\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        img_path = os.path.join(input_folder, image_file)\n",
    "        frame = cv2.imread(img_path)\n",
    "\n",
    "        # Add frame to the video\n",
    "        video.write(frame)\n",
    "        print(f\"Added {image_file} to video.\")\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_video}\")\n",
    "    \n",
    "frames_to_video('film2_png_frames', \"Film2_15fps.avi\", frame_rate=15)\n",
    "\n",
    "def video_to_frames(input_video, output_folder, frame_prefix='frame'):\n",
    "    \"\"\"\n",
    "    Converts a video to individual frames and saves them as images with zero-padded numbering.\n",
    "\n",
    "    Parameters:\n",
    "        input_video (str): Path to the input video file.\n",
    "        output_folder (str): Path to the folder where frames will be saved.\n",
    "        frame_prefix (str): Prefix for the saved frame filenames.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Capture the video\n",
    "    video = cv2.VideoCapture(input_video)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Initialize frame count\n",
    "    frame_count = 1\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break  # Exit loop if there are no frames left to read\n",
    "\n",
    "        # Save each frame with zero-padded numbering\n",
    "        frame_filename = os.path.join(output_folder, f\"{frame_prefix}_{frame_count:04}.png\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        print(f\"Saved frame {frame_count} as {frame_filename}\")\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "    print(f\"Frames saved in folder: {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Stabilization Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stabilize_video(input_path, output_path='stable_video.avi', kp_method='SIFT'):\n",
    "    \"\"\"\n",
    "    Stabilizes a video using a specified keypoint detection method.\n",
    "\n",
    "    Parameters:\n",
    "    - input_path (str): Path to the input video file.\n",
    "    - output_path (str): Path to save the stabilized video.\n",
    "    - kp_method (str): Keypoint detection method to use. Options are 'ORB', 'FAST', 'SIFT', 'SURF'.\n",
    "                       Default is 'SIFT'.\n",
    "    \"\"\"\n",
    "    # Using a specific keypoint detector: keypoint detection method\n",
    "    # ORB (Oriented FAST and Rotated BRIEF): A fast and efficient keypoint detector and descriptor extractor.\n",
    "    # FAST (Features from Accelerated Segment Test): A high-speed keypoint detector.\n",
    "    # SIFT (Scale-Invariant Feature Transform): A robust keypoint detector and descriptor extractor, particularly good for handling scale and rotation variations.\n",
    "    # SURF (Speeded-Up Robust Features): Similar to SIFT but faster, though it is not included in the default OpenCV library due to patent issues.\n",
    "\n",
    "    stabilizer = VidStab(kp_method=kp_method)\n",
    "    stabilizer.stabilize(input_path=input_path, output_path=output_path)\n",
    "\n",
    "# stabilize_video('Film2_15fps.avi', 'Film2_15fps_stable.avi', kp_method='SIFT')\n",
    "\n",
    "def crop_video_after_stabilization(input_video_path=\"stable_video.avi\", output_video_path='cropped_video.avi', crop_x=10, crop_y=10):\n",
    "    \"\"\"\n",
    "    Crop the borders of a stabilized video and resize it back to the original dimensions.\n",
    "    This function reads a stabilized video from the specified input path, crops the borders \n",
    "    by the specified number of pixels, and then resizes the cropped frames back to the original \n",
    "    dimensions before writing them to the specified output path.\n",
    "    Parameters:\n",
    "    input_video_path (str): Path to the input stabilized video file. Default is \"stable_video.avi\".\n",
    "    output_video_path (str): Path to the output cropped video file. Default is 'cropped_video.avi'.\n",
    "    crop_x (int): Number of pixels to crop from the left and right borders of each frame. Default is 10.\n",
    "    crop_y (int): Number of pixels to crop from the top and bottom borders of each frame. Default is 10.\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Get the original frame dimensions\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[crop_y:frame_height-crop_y, crop_x:frame_width-crop_x]\n",
    "\n",
    "        # Resize the cropped frame back to the original dimensions\n",
    "        resized_frame = cv2.resize(cropped_frame, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# crop_video_after_stabilization(\"Film2_15fps_stable.avi\", \"Film2_15fps_stable_cropped10px.avi\", crop_x=10, crop_y=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Illumination Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This\n",
    "\n",
    "def video_to_normalized_frames(input_video_path, output_frames_path, file_prefix='png_frame'):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video, normalizes their illumination, and saves them as individual PNG files.\n",
    "\n",
    "    Parameters:\n",
    "    - input_video_path (str): Path to the input video file.\n",
    "    - output_frames_path (str): Path where the output frames will be saved.\n",
    "    - file_prefix (str): Prefix for the output frame filenames (default: 'png_frame').\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Creates the output folder if it doesn't exist.\n",
    "    2. Extracts frames from the input video.\n",
    "    3. Uses the first frame as a reference for lighting normalization.\n",
    "    4. Normalizes the illumination of each frame to match the reference frame's mean intensity.\n",
    "    5. Saves each normalized frame as a PNG file in the output folder.\n",
    "\n",
    "    The normalized frames are named using the format: {file_prefix}_{frame_number:04d}.png\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    output_folder = os.path.splitext(output_frames_path)[0]\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Extract frames from the video\n",
    "    video = cv2.VideoCapture(input_video_path)\n",
    "    success, image = video.read()\n",
    "    frame_count = 1\n",
    "    if not success:\n",
    "        print(\"Error: Could not read the input video.\")\n",
    "        return\n",
    "\n",
    "    # Read the first frame to use as a reference for lighting normalization\n",
    "    ref_image = np.array(image, dtype=float)\n",
    "    ref_mean = np.mean(ref_image)\n",
    "\n",
    "    while success:\n",
    "        # Load the current frame\n",
    "        img = np.array(image, dtype=float)\n",
    "\n",
    "        # Compute the mean intensity of the current frame\n",
    "        img_mean = np.mean(img)\n",
    "\n",
    "        # Normalize the intensity to match the reference frame's mean\n",
    "        if img_mean > 0:\n",
    "            img_normalized = img * (ref_mean / img_mean)\n",
    "        else:\n",
    "            img_normalized = img  # In case of zero mean (avoid divide by zero)\n",
    "\n",
    "        # Clip the values to ensure they stay in the valid [0, 255] range\n",
    "        img_normalized = np.clip(img_normalized, 0, 255)\n",
    "\n",
    "        # Convert back to uint8\n",
    "        img_normalized_uint8 = img_normalized.astype(np.uint8)\n",
    "\n",
    "        # Save the normalized image as PNG\n",
    "        output_filename = f\"{file_prefix}_{frame_count:04d}.png\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        Image.fromarray(img_normalized_uint8).save(output_path)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "        # Read the next frame\n",
    "        success, image = video.read()\n",
    "        frame_count += 1\n",
    "\n",
    "\n",
    "    # Combine the processed frames into a video\n",
    "    # ... (code for combining frames into a video) ...\n",
    "\n",
    "# video_to_normalized_frames(\"cropped_video.avi\", \"normalized_frames\", file_prefix='normalized_frame')\n",
    "\n",
    "# frames_to_video(\"normalized_frames\", \"video.avi\", frame_rate=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or this\n",
    "\n",
    "def normalize_illumination(input_video_path, output_video_path, frame_rate=30):\n",
    "    \"\"\"\n",
    "    Normalizes the lighting of each frame in the input video and writes the result to a new video file.\n",
    "\n",
    "    Parameters:\n",
    "    - input_video_path (str): Path to the input video file.\n",
    "    - output_video_path (str): Path where the output video file will be saved.\n",
    "    - frame_rate (int): Frame rate of the output video (default: 30).\n",
    "    \"\"\"\n",
    "    # Open the input video\n",
    "    video = cv2.VideoCapture(input_video_path)\n",
    "    success, image = video.read()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"Error: Could not read the input video.\")\n",
    "        return\n",
    "\n",
    "    # Use the first frame as a reference for lighting normalization\n",
    "    ref_image = np.array(image, dtype=float)\n",
    "    ref_mean = np.mean(ref_image)\n",
    "    \n",
    "    # Determine frame dimensions\n",
    "    height, width, _ = image.shape\n",
    "    # Define the video codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Use 'XVID' for .avi format or 'mp4v' for .mp4 format\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    # Initialize frame counter\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Process each frame\n",
    "    while success:\n",
    "        # Convert the current frame to float for processing\n",
    "        img = np.array(image, dtype=float)\n",
    "\n",
    "        # Compute the mean intensity of the current frame\n",
    "        img_mean = np.mean(img)\n",
    "\n",
    "        # Normalize the intensity to match the reference frame's mean\n",
    "        if img_mean > 0:\n",
    "            img_normalized = img * (ref_mean / img_mean)\n",
    "        else:\n",
    "            img_normalized = img  # Avoid divide by zero\n",
    "\n",
    "        # Clip values to [0, 255] and convert back to uint8\n",
    "        img_normalized = np.clip(img_normalized, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Write the normalized frame to the output video\n",
    "        video_writer.write(img_normalized)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "        # Read the next frame\n",
    "        success, image = video.read()\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the VideoWriter and VideoCapture objects\n",
    "    video_writer.release()\n",
    "    video.release()\n",
    "    print(f\"Normalization complete. Video saved as {output_video_path}\")\n",
    "\n",
    "normalize_illumination(\"Film2_15fps_stable_cropped10px.avi\", \"Film2_15fps_stable_cropped10px_normalized.avi\", frame_rate=15)\n",
    "\n",
    "def view_videos_side_by_side(video_path1, video_path2, border_size=10, border_color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Displays two videos side-by-side with borders around each frame.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path1 (str): Path to the first video file.\n",
    "    - video_path2 (str): Path to the second video file.\n",
    "    - border_size (int): Border thickness in pixels (default: 10).\n",
    "    - border_color (tuple): Border color in BGR format (default: white).\n",
    "    \"\"\"\n",
    "    # Read the original and modified videos for display\n",
    "    cap1 = cv2.VideoCapture(video_path1)\n",
    "    cap2 = cv2.VideoCapture(video_path2)\n",
    "    exit_flag = False\n",
    "\n",
    "    while True:  # Outer loop for continuous playback\n",
    "        # Reset video positions when reaching the end\n",
    "        cap1.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "        while cap1.isOpened() and cap2.isOpened():\n",
    "            ret1, frame1 = cap1.read()\n",
    "            ret2, frame2 = cap2.read()\n",
    "\n",
    "            if not ret1 or not ret2:\n",
    "                break  # Break inner loop to restart videos\n",
    "\n",
    "            # Add borders to both frames\n",
    "            frame1_bordered = cv2.copyMakeBorder(\n",
    "                frame1, \n",
    "                border_size, border_size, border_size, border_size,\n",
    "                cv2.BORDER_CONSTANT, \n",
    "                value=border_color\n",
    "            )\n",
    "            frame2_bordered = cv2.copyMakeBorder(\n",
    "                frame2, \n",
    "                border_size, border_size, border_size, border_size,\n",
    "                cv2.BORDER_CONSTANT, \n",
    "                value=border_color\n",
    "            )\n",
    "\n",
    "            # Combine the frames horizontally\n",
    "            combined_frame = cv2.hconcat([frame1_bordered, frame2_bordered])\n",
    "\n",
    "            # If the combined frame is too big, resize it\n",
    "            if combined_frame.shape[1] > 1920:\n",
    "                combined_frame = cv2.resize(combined_frame, (int(combined_frame.shape[1] / 2), int(combined_frame.shape[0] / 2)))\n",
    "\n",
    "            # Display the combined frame\n",
    "            cv2.imshow(f'{video_path1} Vs. {video_path2}, (Press Esc to exit)', combined_frame)\n",
    "\n",
    "            # Check for 'ESC' key press\n",
    "            if cv2.waitKey(1) & 0xFF == 27:  # 27 is the ASCII code for the ESC key\n",
    "                exit_flag = True\n",
    "                break  # Break inner loop\n",
    "\n",
    "        if exit_flag:\n",
    "            break  # Break outer loop\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
